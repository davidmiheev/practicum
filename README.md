# Practicum

## Как генерируются данные

Немного про то как генерирую данные со студентами и их попытками решения заданий на платформе - для этого используется случайный сэмплинг чтобы распределить задачи по модулям и курсам. Попытки решить задачи генерируются со следующими ограничениями: если есть попытка с номером $`X`$ (для данного пользователя и данной задачи), то значит должны быть и все попытки c номерами меньше $`X`$. Количество попыток и результат попытки также определяются случайно. Все манипуляции с данными происходят над `pandas.DataFrame`, в том числе sql-запросы, которые мне нужны - это делается с помощью `duckdb`. Всё это происходит в файле `create_data.py`

## Априорные условия и определения

- Считаем, что мы рассматриваем одну когорту, поэтому количество пользователей небольшое и не содержит тёсок (хочется смотреть на имена студентов, а не на id в дэше)
- Задачи считаются адекватными по сложности - на это ориентировался когда генерировал данные по попыткам решить задачи
- Считаем, что макcимальное количество попыток решить задание равно 10
- Сложность задачи считается как среднее количество попыток, которое требуется чтобы решить эту задачу пользователями; *логика: если задачу пытаются решить много раз до того как получится её решить - это сложная задача (альтернативный подход смотреть на процент пользователей решивших задачу с n-той попытки)*
- Каждому курсу в каждом модуле приписывается вовлечённость студента (оцениваемая кураторами и ревьюерами), удовлетворённость курсом (оцениваемая самим студентом), генерируются с помощью нормального распределения
- У каждого студента есть прогресс по курсу который имеет прирост (генерируется нормальным распределением) каждую неделю, в данных изменение прогресса в течение 4 недель

## Follow up

Что можно ещё джобавить в данные:
- [done] Оценки интересности заданий, указанные пользователями на платформе
